<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 9 Multiple regression | Are you ready for R? A Workbook for R for Political Science and Beyond: Version 3.0</title>
  <meta name="description" content="This is the preface of the workbook" />
  <meta name="generator" content="bookdown 0.37 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 9 Multiple regression | Are you ready for R? A Workbook for R for Political Science and Beyond: Version 3.0" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This is the preface of the workbook" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 9 Multiple regression | Are you ready for R? A Workbook for R for Political Science and Beyond: Version 3.0" />
  
  <meta name="twitter:description" content="This is the preface of the workbook" />
  

<meta name="author" content="Michael Strausz" />


<meta name="date" content="2025-07-03" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="pearsons-r.html"/>
<link rel="next" href="wild.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Are You Ready for R?</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="" data-path="about-the-author.html"><a href="about-the-author.html"><i class="fa fa-check"></i>About the author</a></li>
<li class="chapter" data-level="" data-path="acknowledgements.html"><a href="acknowledgements.html"><i class="fa fa-check"></i>Acknowledgements</a></li>
<li class="chapter" data-level="" data-path="whats-new-in-version-3.html"><a href="whats-new-in-version-3.html"><i class="fa fa-check"></i>What’s new in version 3.0?</a></li>
<li class="chapter" data-level="1" data-path="getting-started.html"><a href="getting-started.html"><i class="fa fa-check"></i><b>1</b> Getting started with R</a>
<ul>
<li class="chapter" data-level="1.1" data-path="getting-started.html"><a href="getting-started.html#why-r"><i class="fa fa-check"></i><b>1.1</b> Why R?</a></li>
<li class="chapter" data-level="1.2" data-path="getting-started.html"><a href="getting-started.html#class-project"><i class="fa fa-check"></i><b>1.2</b> Create a project for this class</a></li>
<li class="chapter" data-level="1.3" data-path="getting-started.html"><a href="getting-started.html#add-files"><i class="fa fa-check"></i><b>1.3</b> Add the course files to your project</a></li>
<li class="chapter" data-level="1.4" data-path="getting-started.html"><a href="getting-started.html#using-the-console"><i class="fa fa-check"></i><b>1.4</b> Using the Console</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="getting-started.html"><a href="getting-started.html#rules-about-naming-objects"><i class="fa fa-check"></i><b>1.4.1</b> Rules about naming objects</a></li>
<li class="chapter" data-level="1.4.2" data-path="getting-started.html"><a href="getting-started.html#common-practices-when-naming-objects"><i class="fa fa-check"></i><b>1.4.2</b> Common practices when naming objects</a></li>
<li class="chapter" data-level="1.4.3" data-path="getting-started.html"><a href="getting-started.html#about-vectors"><i class="fa fa-check"></i><b>1.4.3</b> About vectors</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="getting-started.html"><a href="getting-started.html#first-script"><i class="fa fa-check"></i><b>1.5</b> Writing your first R script</a></li>
<li class="chapter" data-level="1.6" data-path="getting-started.html"><a href="getting-started.html#wont-load"><i class="fa fa-check"></i><b>1.6</b> What do to if the “load” command doesn’t load the dataframe</a></li>
<li class="chapter" data-level="1.7" data-path="getting-started.html"><a href="getting-started.html#review-of-this-chapters-commands"><i class="fa fa-check"></i><b>1.7</b> Review of this chapter’s commands</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="tidyverse.html"><a href="tidyverse.html"><i class="fa fa-check"></i><b>2</b> Welcome to the tidyverse</a>
<ul>
<li class="chapter" data-level="2.1" data-path="tidyverse.html"><a href="tidyverse.html#install-tidyverse"><i class="fa fa-check"></i><b>2.1</b> Installing packages</a></li>
<li class="chapter" data-level="2.2" data-path="tidyverse.html"><a href="tidyverse.html#exploring"><i class="fa fa-check"></i><b>2.2</b> Exploring dataframes</a></li>
<li class="chapter" data-level="2.3" data-path="tidyverse.html"><a href="tidyverse.html#org-script"><i class="fa fa-check"></i><b>2.3</b> Organizing your scripts</a></li>
<li class="chapter" data-level="2.4" data-path="tidyverse.html"><a href="tidyverse.html#welcome-to-the-tidyverse"><i class="fa fa-check"></i><b>2.4</b> Welcome to the tidyverse</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="tidyverse.html"><a href="tidyverse.html#introducing-the-pipe-in-tidyverse"><i class="fa fa-check"></i><b>2.4.1</b> Introducing the ‘pipe’ in tidyverse</a></li>
<li class="chapter" data-level="2.4.2" data-path="tidyverse.html"><a href="tidyverse.html#select-in-tidyverse"><i class="fa fa-check"></i><b>2.4.2</b> select() in tidyverse</a></li>
<li class="chapter" data-level="2.4.3" data-path="tidyverse.html"><a href="tidyverse.html#a-warning-about-the-select-command"><i class="fa fa-check"></i><b>2.4.3</b> A warning about the select() command</a></li>
<li class="chapter" data-level="2.4.4" data-path="tidyverse.html"><a href="tidyverse.html#arrange-in-tidyverse"><i class="fa fa-check"></i><b>2.4.4</b> arrange() in tidyverse</a></li>
<li class="chapter" data-level="2.4.5" data-path="tidyverse.html"><a href="tidyverse.html#glimpse-in-tidyverse"><i class="fa fa-check"></i><b>2.4.5</b> glimpse() in tidyverse</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="tidyverse.html"><a href="tidyverse.html#review-of-this-chapters-commands-1"><i class="fa fa-check"></i><b>2.5</b> Review of this chapter’s commands</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="graphing.html"><a href="graphing.html"><i class="fa fa-check"></i><b>3</b> Graphing and describing variables</a>
<ul>
<li class="chapter" data-level="3.1" data-path="graphing.html"><a href="graphing.html#getting-started-tidyverse"><i class="fa fa-check"></i><b>3.1</b> Getting started with this chapter</a></li>
<li class="chapter" data-level="3.2" data-path="graphing.html"><a href="graphing.html#start-graphing"><i class="fa fa-check"></i><b>3.2</b> Getting started with ggplot and graphing</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="graphing.html"><a href="graphing.html#bar-graph-nominal"><i class="fa fa-check"></i><b>3.2.1</b> Bar graphing a nominal variable</a></li>
<li class="chapter" data-level="3.2.2" data-path="graphing.html"><a href="graphing.html#remove-na"><i class="fa fa-check"></i><b>3.2.2</b> Removing the NA bar</a></li>
<li class="chapter" data-level="3.2.3" data-path="graphing.html"><a href="graphing.html#add-return"><i class="fa fa-check"></i><b>3.2.3</b> Adding a second line to a graph’s title</a></li>
<li class="chapter" data-level="3.2.4" data-path="graphing.html"><a href="graphing.html#saving-a-graph"><i class="fa fa-check"></i><b>3.2.4</b> Saving a graph</a></li>
<li class="chapter" data-level="3.2.5" data-path="graphing.html"><a href="graphing.html#bar-graph-ordinal"><i class="fa fa-check"></i><b>3.2.5</b> Bar graphing an ordinal variable</a></li>
<li class="chapter" data-level="3.2.6" data-path="graphing.html"><a href="graphing.html#what-to-do-about-overlapping-labels"><i class="fa fa-check"></i><b>3.2.6</b> What to do about overlapping labels</a></li>
<li class="chapter" data-level="3.2.7" data-path="graphing.html"><a href="graphing.html#histogram"><i class="fa fa-check"></i><b>3.2.7</b> Generating a histogram</a></li>
<li class="chapter" data-level="3.2.8" data-path="graphing.html"><a href="graphing.html#removing-scientific-notation-from-axes"><i class="fa fa-check"></i><b>3.2.8</b> Removing scientific notation from axes</a></li>
<li class="chapter" data-level="3.2.9" data-path="graphing.html"><a href="graphing.html#adjusting-bin-width-on-a-histogram"><i class="fa fa-check"></i><b>3.2.9</b> Adjusting bin width on a histogram</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="graphing.html"><a href="graphing.html#central-tendancy-and-dispersion"><i class="fa fa-check"></i><b>3.3</b> Central tendancy and dispersion</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="graphing.html"><a href="graphing.html#central-tendency-and-dispersion-of-nominal-variables"><i class="fa fa-check"></i><b>3.3.1</b> Central tendency and dispersion of nominal variables</a></li>
<li class="chapter" data-level="3.3.2" data-path="graphing.html"><a href="graphing.html#central-tendency-and-dispersion-of-ordinal-variables"><i class="fa fa-check"></i><b>3.3.2</b> Central tendency and dispersion of ordinal variables</a></li>
<li class="chapter" data-level="3.3.3" data-path="graphing.html"><a href="graphing.html#central-tendancy-and-dispersion-of-interval-variables"><i class="fa fa-check"></i><b>3.3.3</b> Central tendancy and dispersion of interval variables</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="graphing.html"><a href="graphing.html#states-world"><i class="fa fa-check"></i><b>3.4</b> A note on using the states2025 and world2025</a></li>
<li class="chapter" data-level="3.5" data-path="graphing.html"><a href="graphing.html#review-of-this-chapters-commands-2"><i class="fa fa-check"></i><b>3.5</b> Review of this chapter’s commands</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="recoding.html"><a href="recoding.html"><i class="fa fa-check"></i><b>4</b> Recoding and comparing values of variables</a>
<ul>
<li class="chapter" data-level="4.1" data-path="recoding.html"><a href="recoding.html#getting-started-recoding"><i class="fa fa-check"></i><b>4.1</b> Getting started with this chapter</a></li>
<li class="chapter" data-level="4.2" data-path="recoding.html"><a href="recoding.html#recode-nom"><i class="fa fa-check"></i><b>4.2</b> Recoding ordinal and nominal variables</a></li>
<li class="chapter" data-level="4.3" data-path="recoding.html"><a href="recoding.html#reverse-ord"><i class="fa fa-check"></i><b>4.3</b> Reversing the order of ordinal variables</a></li>
<li class="chapter" data-level="4.4" data-path="recoding.html"><a href="recoding.html#factor-as-numeric"><i class="fa fa-check"></i><b>4.4</b> Making ordinal variables numeric</a></li>
<li class="chapter" data-level="4.5" data-path="recoding.html"><a href="recoding.html#recode-dummy"><i class="fa fa-check"></i><b>4.5</b> Dealing with variables coded 0/1</a></li>
<li class="chapter" data-level="4.6" data-path="recoding.html"><a href="recoding.html#simp-int"><i class="fa fa-check"></i><b>4.6</b> Simplifying interval variables</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="recoding.html"><a href="recoding.html#cut-2"><i class="fa fa-check"></i><b>4.6.1</b> Simplifying interval variables using cut2()</a></li>
<li class="chapter" data-level="4.6.2" data-path="recoding.html"><a href="recoding.html#case-when"><i class="fa fa-check"></i><b>4.6.2</b> Simplifying interval variables with case_when</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="recoding.html"><a href="recoding.html#cross-tabs"><i class="fa fa-check"></i><b>4.7</b> Cross-tabulation tables</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="recoding.html"><a href="recoding.html#generating-cross-tabs"><i class="fa fa-check"></i><b>4.7.1</b> Generating cross-tabs</a></li>
<li class="chapter" data-level="4.7.2" data-path="recoding.html"><a href="recoding.html#adding-column-totals-to-cross-tabs"><i class="fa fa-check"></i><b>4.7.2</b> Adding column totals to cross-tabs</a></li>
<li class="chapter" data-level="4.7.3" data-path="recoding.html"><a href="recoding.html#column-percents"><i class="fa fa-check"></i><b>4.7.3</b> Adding column percents to cross-tabs</a></li>
<li class="chapter" data-level="4.7.4" data-path="recoding.html"><a href="recoding.html#export-crosstabs"><i class="fa fa-check"></i><b>4.7.4</b> Exporting cross-tabs for your word processor</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="recoding.html"><a href="recoding.html#mean-comparison-tables"><i class="fa fa-check"></i><b>4.8</b> Mean comparison tables</a></li>
<li class="chapter" data-level="4.9" data-path="recoding.html"><a href="recoding.html#review-of-this-chapters-commands-3"><i class="fa fa-check"></i><b>4.9</b> Review of this chapter’s commands</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="making-controlled-comparisons.html"><a href="making-controlled-comparisons.html"><i class="fa fa-check"></i><b>5</b> Making controlled comparisons</a>
<ul>
<li class="chapter" data-level="5.1" data-path="making-controlled-comparisons.html"><a href="making-controlled-comparisons.html#getting-started-comparisons"><i class="fa fa-check"></i><b>5.1</b> Getting started with this chapter</a></li>
<li class="chapter" data-level="5.2" data-path="making-controlled-comparisons.html"><a href="making-controlled-comparisons.html#stacked"><i class="fa fa-check"></i><b>5.2</b> Representing crosstabs with stacked bar graphs</a></li>
<li class="chapter" data-level="5.3" data-path="making-controlled-comparisons.html"><a href="making-controlled-comparisons.html#representing-mean-comparison-tables-with-boxplots"><i class="fa fa-check"></i><b>5.3</b> Representing mean comparison tables with boxplots</a></li>
<li class="chapter" data-level="5.4" data-path="making-controlled-comparisons.html"><a href="making-controlled-comparisons.html#adding-a-control-to-a-crosstab"><i class="fa fa-check"></i><b>5.4</b> Adding a control to a crosstab</a></li>
<li class="chapter" data-level="5.5" data-path="making-controlled-comparisons.html"><a href="making-controlled-comparisons.html#adding-a-control-to-a-mean-comparison-table"><i class="fa fa-check"></i><b>5.5</b> Adding a control to a mean comparison table</a></li>
<li class="chapter" data-level="5.6" data-path="making-controlled-comparisons.html"><a href="making-controlled-comparisons.html#review-of-this-chapters-commands-4"><i class="fa fa-check"></i><b>5.6</b> Review of this chapter’s commands</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="inferences.html"><a href="inferences.html"><i class="fa fa-check"></i><b>6</b> Making inferences from sample means</a>
<ul>
<li class="chapter" data-level="6.1" data-path="inferences.html"><a href="inferences.html#getting-started-inferences"><i class="fa fa-check"></i><b>6.1</b> Getting started with this chapter</a></li>
<li class="chapter" data-level="6.2" data-path="inferences.html"><a href="inferences.html#constructing-a-confidence-interval-around-a-mean"><i class="fa fa-check"></i><b>6.2</b> Constructing a confidence interval around a mean</a></li>
<li class="chapter" data-level="6.3" data-path="inferences.html"><a href="inferences.html#ci-around-proportion"><i class="fa fa-check"></i><b>6.3</b> Constructing a confidence interval around a proportion</a></li>
<li class="chapter" data-level="6.4" data-path="inferences.html"><a href="inferences.html#ci-around-proportions"><i class="fa fa-check"></i><b>6.4</b> Constructing confidence intervals around several proportions at once</a></li>
<li class="chapter" data-level="6.5" data-path="inferences.html"><a href="inferences.html#t-test-ind-means"><i class="fa fa-check"></i><b>6.5</b> T-test of independent means</a></li>
<li class="chapter" data-level="6.6" data-path="inferences.html"><a href="inferences.html#caution-about-statistical-significance"><i class="fa fa-check"></i><b>6.6</b> Caution about “statistical significance”</a></li>
<li class="chapter" data-level="6.7" data-path="inferences.html"><a href="inferences.html#t-test-ind-props"><i class="fa fa-check"></i><b>6.7</b> T-test of independent proportions</a></li>
<li class="chapter" data-level="6.8" data-path="inferences.html"><a href="inferences.html#review-of-this-chapters-commands-5"><i class="fa fa-check"></i><b>6.8</b> Review of this chapter’s commands</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="chi-squared-etc.html"><a href="chi-squared-etc.html"><i class="fa fa-check"></i><b>7</b> From chi-squared to somers’ d</a>
<ul>
<li class="chapter" data-level="7.1" data-path="chi-squared-etc.html"><a href="chi-squared-etc.html#getting-started-chi"><i class="fa fa-check"></i><b>7.1</b> Getting started with this chapter</a></li>
<li class="chapter" data-level="7.2" data-path="chi-squared-etc.html"><a href="chi-squared-etc.html#chi-squared"><i class="fa fa-check"></i><b>7.2</b> Calculating chi-squared</a></li>
<li class="chapter" data-level="7.3" data-path="chi-squared-etc.html"><a href="chi-squared-etc.html#lambda"><i class="fa fa-check"></i><b>7.3</b> Lambda and the PREs</a></li>
<li class="chapter" data-level="7.4" data-path="chi-squared-etc.html"><a href="chi-squared-etc.html#cramers-v"><i class="fa fa-check"></i><b>7.4</b> Cramer’s V</a></li>
<li class="chapter" data-level="7.5" data-path="chi-squared-etc.html"><a href="chi-squared-etc.html#somers-d"><i class="fa fa-check"></i><b>7.5</b> Somers’ D</a></li>
<li class="chapter" data-level="7.6" data-path="chi-squared-etc.html"><a href="chi-squared-etc.html#review-of-this-chapters-commands-6"><i class="fa fa-check"></i><b>7.6</b> Review of this chapter’s commands</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="pearsons-r.html"><a href="pearsons-r.html"><i class="fa fa-check"></i><b>8</b> Pearson’s r and linear regression</a>
<ul>
<li class="chapter" data-level="8.1" data-path="pearsons-r.html"><a href="pearsons-r.html#getting-started-pearsons-r"><i class="fa fa-check"></i><b>8.1</b> Getting started with this chapter</a></li>
<li class="chapter" data-level="8.2" data-path="pearsons-r.html"><a href="pearsons-r.html#pearsons-r-1"><i class="fa fa-check"></i><b>8.2</b> Pearson’s R</a></li>
<li class="chapter" data-level="8.3" data-path="pearsons-r.html"><a href="pearsons-r.html#scatterplot"><i class="fa fa-check"></i><b>8.3</b> The scatterplot</a></li>
<li class="chapter" data-level="8.4" data-path="pearsons-r.html"><a href="pearsons-r.html#bivariate-regression"><i class="fa fa-check"></i><b>8.4</b> Bivariate linear regression</a></li>
<li class="chapter" data-level="8.5" data-path="pearsons-r.html"><a href="pearsons-r.html#residuals"><i class="fa fa-check"></i><b>8.5</b> Residuals</a></li>
<li class="chapter" data-level="8.6" data-path="pearsons-r.html"><a href="pearsons-r.html#review-of-this-chapters-commands-7"><i class="fa fa-check"></i><b>8.6</b> Review of this chapter’s commands</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="regression.html"><a href="regression.html"><i class="fa fa-check"></i><b>9</b> Multiple regression</a>
<ul>
<li class="chapter" data-level="9.1" data-path="regression.html"><a href="regression.html#getting-started-multiple-regression"><i class="fa fa-check"></i><b>9.1</b> Getting started with this chapter</a></li>
<li class="chapter" data-level="9.2" data-path="regression.html"><a href="regression.html#multiple-regression"><i class="fa fa-check"></i><b>9.2</b> Multiple regression</a></li>
<li class="chapter" data-level="9.3" data-path="regression.html"><a href="regression.html#residuals-in-multiple-regression"><i class="fa fa-check"></i><b>9.3</b> Residuals in multiple regression</a></li>
<li class="chapter" data-level="9.4" data-path="regression.html"><a href="regression.html#stargazer"><i class="fa fa-check"></i><b>9.4</b> Stargazer output</a></li>
<li class="chapter" data-level="9.5" data-path="regression.html"><a href="regression.html#dummy-variables-in-multiple-regression"><i class="fa fa-check"></i><b>9.5</b> Dummy variables in multiple regression</a></li>
<li class="chapter" data-level="9.6" data-path="regression.html"><a href="regression.html#ordinal-variables-in-regression-analysis"><i class="fa fa-check"></i><b>9.6</b> Ordinal variables in regression analysis</a></li>
<li class="chapter" data-level="9.7" data-path="regression.html"><a href="regression.html#graphing-multiple-regression"><i class="fa fa-check"></i><b>9.7</b> Graphing multiple regression</a></li>
<li class="chapter" data-level="9.8" data-path="regression.html"><a href="regression.html#review-of-this-chapters-commands-8"><i class="fa fa-check"></i><b>9.8</b> Review of this chapter’s commands</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="wild.html"><a href="wild.html"><i class="fa fa-check"></i><b>10</b> R in the wild</a>
<ul>
<li class="chapter" data-level="10.1" data-path="wild.html"><a href="wild.html#todays-lab-as-a-reference"><i class="fa fa-check"></i><b>10.1</b> Today’s lab as a reference</a></li>
<li class="chapter" data-level="10.2" data-path="wild.html"><a href="wild.html#importing-data-into-r"><i class="fa fa-check"></i><b>10.2</b> Importing data into R</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="wild.html"><a href="wild.html#importing-csv-files"><i class="fa fa-check"></i><b>10.2.1</b> Importing CSV files</a></li>
<li class="chapter" data-level="10.2.2" data-path="wild.html"><a href="wild.html#importing-excel-files"><i class="fa fa-check"></i><b>10.2.2</b> Importing Excel files</a></li>
<li class="chapter" data-level="10.2.3" data-path="wild.html"><a href="wild.html#importing-other-files"><i class="fa fa-check"></i><b>10.2.3</b> Importing other files</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="wild.html"><a href="wild.html#cleaning-data-in-r"><i class="fa fa-check"></i><b>10.3</b> Cleaning data in R</a></li>
<li class="chapter" data-level="10.4" data-path="wild.html"><a href="wild.html#resources"><i class="fa fa-check"></i><b>10.4</b> Online R resources</a></li>
<li class="chapter" data-level="10.5" data-path="wild.html"><a href="wild.html#the-last-command-how-to-get-help"><i class="fa fa-check"></i><b>10.5</b> The last command: how to get help</a></li>
<li class="chapter" data-level="10.6" data-path="wild.html"><a href="wild.html#the-strausz-method-for-improving-in-r"><i class="fa fa-check"></i><b>10.6</b> The Strausz method for improving in R</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Are you ready for R? A Workbook for R for Political Science and Beyond: Version 3.0</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="regression" class="section level1 hasAnchor" number="9">
<h1><span class="header-section-number">Chapter 9</span> Multiple regression<a href="regression.html#regression" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="getting-started-multiple-regression" class="section level2 hasAnchor" number="9.1">
<h2><span class="header-section-number">9.1</span> Getting started with this chapter<a href="regression.html#getting-started-multiple-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>To get started in today’s chapter, open the project that you made in lab 1. If you forgot how to do this, see the instructions in section <a href="tidyverse.html#exploring">2.2</a>.</p>
<p>Now type <code>install.packages("stargazer")</code> into the Console.<a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a> This new package will help us label our graphs in a way that is easier to read.</p>
<p>Next, open a new script file and save it in your scripts folder as “chapter 9 practice.” Write this on the page:</p>
<pre><code>####################################
# Your name
# 20093 Chapter 9, Practice exercises
# Date started : Date last modified
####################################

#libraries------------------------------------------
library(tidyverse)
library(ggrepel)
library(modelr)
library(stargazer)</code></pre>
<p>Now select all the text on this page, run it, and then save it.</p>
</div>
<div id="multiple-regression" class="section level2 hasAnchor" number="9.2">
<h2><span class="header-section-number">9.2</span> Multiple regression<a href="regression.html#multiple-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In the last chapter, we learned how to do bivariate ordinary least squared (OLS) regression. This is an extremely powerful tool for statistical inference because it both provides a proportional reduction in error estimate (<span class="math inline">\(R^2\)</span>), which tells us exactly how much of the variation in our dependent variable is explained by variation in our independent variable, and it provides us with a coefficient estimate, which tells us exactly what we expect to happen to our dependent variable with every one unit increase in our independent variable.</p>
<p>But there is one more reason that regression is a tool beloved by scientists. It provides an easy way to control for many different independent variables at the same time. Recall that in Chapter 8 we discussed how when R is running a regression it is estimating the values of M and B in the formula Y=MX+B. Another way that we can write that same formula is like this:
<span class="math display">\[Y=β_0+ β_1X_1\]</span>
In this version of the formula, we call the intercept <span class="math inline">\(β_0\)</span> (β is the Greek letter Beta) instead of B, and we call the slope <span class="math inline">\(β_1\)</span> instead of M. When conducting bivariate regression, we are asking R to give us the values of <span class="math inline">\(β_0\)</span> (the intercept, or B) and <span class="math inline">\(β_1\)</span> (the slope, or M) that best fits our data. When we want to conduct multiple regression, we can use the same principle, but we just have to add more independent variables and βs, like this:
<span class="math display">\[Y=β_0+ β_1X_1 + β_2X_2 + β_3X_3+…+ β_nX_n\]</span>
Multiple regression results include an estimate for all of those βs. The estimates are called “partial regression coefficients,” which is generally shortened to “coefficients.” And they are very powerful! In the above equation, R’s estimated value for <span class="math inline">\(β_1\)</span> tells us what we expect to happen to our dependent variable, Y, when we increase <span class="math inline">\(X_1\)</span> by one unit, and when we hold <span class="math inline">\(X_2\)</span>, <span class="math inline">\(X_3\)</span>, and all other independent variables in our equation constant. Thus, if someone were to say “Hey, I think that the relationship that you observe between <span class="math inline">\(X_1\)</span> and Y is spurious; variation in <span class="math inline">\(X_2\)</span>, which happens to be correlated with <span class="math inline">\(X_1\)</span>, is the actual cause of variation in Y!” You can reply, “in this multiple regression, I controlled for <span class="math inline">\(X_2\)</span> (in other words, I looked at the relationship between <span class="math inline">\(X_1\)</span> and Y at similar values of <span class="math inline">\(X_2\)</span>) and I still found a meaningful relationship between <span class="math inline">\(X_1\)</span> and Y. Thus, I can rule out spuriousness!”</p>
<p>Let’s try an example, returning to our regression analysis from Chapter <a href="pearsons-r.html#pearsons-r">8</a>, where we looked at reaganMargin1980 as our dependent variable trumpMargin2024 as our dependent variable. To test this analysis, we ran the following regression:</p>
<div class="sourceCode" id="cb219"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb219-1"><a href="regression.html#cb219-1" tabindex="-1"></a>model1<span class="ot">&lt;-</span><span class="fu">lm</span>(<span class="at">formula =</span> trumpMargin2024 <span class="sc">~</span> reaganMargin1980, <span class="at">data =</span> states2025)</span>
<span id="cb219-2"><a href="regression.html#cb219-2" tabindex="-1"></a><span class="co">#now we ask R to display the results of that analysis</span></span>
<span id="cb219-3"><a href="regression.html#cb219-3" tabindex="-1"></a>model1</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = trumpMargin2024 ~ reaganMargin1980, data = states2025)
## 
## Coefficients:
##      (Intercept)  reaganMargin1980  
##         -0.03344           0.72737</code></pre>
<p>This output helped us write the equation for the relationship between reaganMargin1980 and trumpMargin2024:</p>
<p>trumpMargin2024 = -.03344 + -0.72737 (reaganMargin1980)</p>
<p>So in other words, R is estimating that a in state where Reagan and Carter in tied in 1980 (and thus Reagan’s margin was 0), Trump would lose by a proportion of .03344 (or about 3.3%), and that, if a state’s reaganMargin increased by 1 (moving from a score of 0, where Reagan and Carter tied, to a 1, which means that Reagan won 100% of the vote), Trump’s margin of victory would increase by .72737, or about 72.7%.</p>
<p>To determine whether these estimates are statistically significant, we summarized our regression model, like this:</p>
<div class="sourceCode" id="cb221"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb221-1"><a href="regression.html#cb221-1" tabindex="-1"></a><span class="fu">summary</span>(model1)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = trumpMargin2024 ~ reaganMargin1980, data = states2025)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.35722 -0.15308  0.00016  0.11850  0.48517 
## 
## Coefficients:
##                  Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)      -0.03344    0.03276  -1.021    0.312    
## reaganMargin1980  0.72737    0.15504   4.692 2.21e-05 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.197 on 49 degrees of freedom
## Multiple R-squared:   0.31,  Adjusted R-squared:  0.2959 
## F-statistic: 22.01 on 1 and 49 DF,  p-value: 2.208e-05</code></pre>
<p>This output shows us that the estimates of the slope and intercept are both statistically significant, and that the adjusted <span class="math inline">\(R_2\)</span> is .2959, which means that variation Reagan’s margin in 1980 explain about 29.59% of variation in Trump’s margin in 2024.</p>
<p>That is pretty good! We can learn a lot about how states voted in 2024 by observing how they voted in 1980. However, we also know that there is still a lot of variation that is unexplained. Thinking back to our analysis of residuals in section <a href="pearsons-r.html#residuals">8.5</a>, we know that, while our regression analysis does a pretty good job of explaining Michigan, it does a much less good job of explaining West Virginia.</p>
<p>Moreover, what if there is a variable that is correlated with reaganMargin1980 but which is the true cause of trumpMargin2024? If that were the case, and if we add that new independent variable to our regression analysis, then the relationship between reaganMargin1980 and trumpMargin2024 would no longer be statistically significant, and we would say that the relationship between reaganMargin and trumpMargin that we had observed is spurious.</p>
<p>One additional variable which might help explain Trump’s margin of victory in 2024 is the percentage of a state’s population that is evangelical, since evangelical Christians are an increasingly important constituency of the Republican party. When we control for percent evangelical, does reaganMargin1980 still help explain trumpMargin2024? To help us answer this question, we need to have R estimate <span class="math inline">\(β_1\)</span> and <span class="math inline">\(β_2\)</span> in this formula:</p>
<p>trumpMargin2024=<span class="math inline">\(β_0\)</span> + <span class="math inline">\(β_1\)</span>reaganMargin1980 + <span class="math inline">\(β_2\)</span>evanPerc2020</p>
<p>We can do that with this command:</p>
<div class="sourceCode" id="cb223"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb223-1"><a href="regression.html#cb223-1" tabindex="-1"></a>model2<span class="ot">&lt;-</span><span class="fu">lm</span>(<span class="at">formula =</span> trumpMargin2024 <span class="sc">~</span> reaganMargin1980<span class="sc">+</span>evanPerc2020, <span class="at">data =</span> states2025)</span>
<span id="cb223-2"><a href="regression.html#cb223-2" tabindex="-1"></a><span class="fu">summary</span>(model2)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = trumpMargin2024 ~ reaganMargin1980 + evanPerc2020, 
##     data = states2025)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.29391 -0.07966  0.00576  0.07360  0.50405 
## 
## Coefficients:
##                   Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)      -0.274902   0.041992  -6.546 3.65e-08 ***
## reaganMargin1980  0.876417   0.112853   7.766 4.98e-10 ***
## evanPerc2020      0.013624   0.001967   6.926 9.55e-09 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.1408 on 48 degrees of freedom
## Multiple R-squared:  0.6549, Adjusted R-squared:  0.6405 
## F-statistic: 45.54 on 2 and 48 DF,  p-value: 8.155e-12</code></pre>
<p>Looking at the Pr(&gt;|t|) column in this output, we can see that the intercept and both coefficient estimates are statistically significant, because the numbers are much, much lower than .05. The value of adjusted <span class="math inline">\(R_2\)</span> is .6405, which means that variation in reaganMargin and percent evangelical explains about 64% of variation in trumpMargin2024.</p>
<p>trumpMargin2024 = -.2749 + .8764reaganMargin1980 + .0136evanPerc2020</p>
<p>This equation is telling us that, based on our data, R predicts that in a state where Reagan and Carter tied in 1980 (creating a reaganMargin1980 of 0),with 0 evangelical Christians, Trump would have lost to Harris by .2749, or 27.49%. However, holding the percent of evangelicals in that state constant, if we increase Reagan’s margin of victory in 1980 from 0 to 1 (or from 0% to 100%), then we expect Trump’s margin of victory in 2024 to increase by .8764, or 87.64%. Moreover, holding Reagan’s margin in 1980 constant, an 1% increase of the percentage of evangelical Christians in a state is associated with a .0136 increase in trumpMargin2024 (or a 1.36% increase in Trump’s margin of victory). In other words we know that the partial relationship between Reagan margin and Trump margin, controlling for evangelical population, is not spurious.</p>
</div>
<div id="residuals-in-multiple-regression" class="section level2 hasAnchor" number="9.3">
<h2><span class="header-section-number">9.3</span> Residuals in multiple regression<a href="regression.html#residuals-in-multiple-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We can also apply the same principles that we used in section <a href="pearsons-r.html#residuals">8.5</a> to see which of our cases are really well explained by our model (with residuals that are close to 0) and which are less well explained by our model:</p>
<div class="sourceCode" id="cb225"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb225-1"><a href="regression.html#cb225-1" tabindex="-1"></a>model2.data<span class="ot">&lt;-</span>states2025 <span class="sc">%&gt;%</span> </span>
<span id="cb225-2"><a href="regression.html#cb225-2" tabindex="-1"></a>  <span class="fu">add_predictions</span>(model2) <span class="sc">%&gt;%</span> </span>
<span id="cb225-3"><a href="regression.html#cb225-3" tabindex="-1"></a>  <span class="fu">add_residuals</span>(model2)</span>
<span id="cb225-4"><a href="regression.html#cb225-4" tabindex="-1"></a>model2.data<span class="sc">$</span>abs.resid<span class="ot">&lt;-</span><span class="fu">abs</span>(model2.data<span class="sc">$</span>resid)</span></code></pre></div>
<p>Now let’s look at the states with the residuals that are the farthest from zero:</p>
<div class="sourceCode" id="cb226"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb226-1"><a href="regression.html#cb226-1" tabindex="-1"></a>model2.data <span class="sc">%&gt;%</span> </span>
<span id="cb226-2"><a href="regression.html#cb226-2" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">select</span>(state,abs.resid) <span class="sc">%&gt;%</span></span>
<span id="cb226-3"><a href="regression.html#cb226-3" tabindex="-1"></a>  <span class="fu">arrange</span>(<span class="fu">desc</span>(abs.resid)) <span class="sc">%&gt;%</span> </span>
<span id="cb226-4"><a href="regression.html#cb226-4" tabindex="-1"></a>  <span class="fu">head</span>()</span></code></pre></div>
<pre><code>## # A tibble: 6 × 2
##   state                abs.resid
##   &lt;chr&gt;                    &lt;dbl&gt;
## 1 West Virginia            0.504
## 2 Washington               0.294
## 3 Wyoming                  0.276
## 4 District of Columbia     0.232
## 5 Colorado                 0.205
## 6 California               0.196</code></pre>
<p>Just like the bivariate regression, West Virginia remains the state with the residual that is the farthest from 0 (the state that our regression has the most trouble explaining). DC also remains in our top six, but other than those two, we can see that, with our multiple regression the other four states with the residuals farthest from zero are not in the South (Washington, Wyoming, Colorado, and California). This might suggest that the percent evangelical was important driver of Trump’s margin of victory in the South in 2024, and that was not captured by our first regression. If you run the same command in without <code>desc()</code>, you will see that Michigan, which was the case that our bivariate regression explained the best, is no longer in the top six best explained cases of our multivariate regression.<a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a></p>
</div>
<div id="stargazer" class="section level2 hasAnchor" number="9.4">
<h2><span class="header-section-number">9.4</span> Stargazer output<a href="regression.html#stargazer" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The output that we generated in the last section is pretty difficult to read, and would not look good in a paper. But, we have a nice solution – the stargazer package that we installed above! Once we have installed and loaded that package, we can invoke it like this:</p>
<pre><code>stargazer(model1, model2, type=&quot;html&quot;, out=&quot;lab9regressions.html&quot;,
          column.labels = c(&quot;Model 1&quot;, &quot;Model 2&quot;), 
          single.row=FALSE,     
          notes.append = FALSE, 
          header=FALSE)</code></pre>
<p>This is telling R to make a table with regression results from both of our regressions and to save it as a file called lab9regressions.html. If you want to change the name, you can just change what you write in the quotes after “out=”. Just don’t type any periods before .html, and keep the .html at the end. If you have more than two models that you want to run, you can just add them, but you have to add as many labels as you have models after column.labels.</p>
<p>When you run this command, a bunch of gibberish will pop up in your consol. Don’t worry about that. Just look in the main folder where you have your Scope and Methods labs project stored. There, you should see an html file called “lab9regressions.html” (unless you changed the name to something else). Open that file – it should open in your web browser. Highlight all of the text, copy it (using Ctrl-C on a Windows machine or Command-C on a Mac), and paste it into a word processor document. You should see something like this:</p>
<table style="text-align:center">
<tr>
<td colspan="3" style="border-bottom: 1px solid black">
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td colspan="2">
<em>Dependent variable:</em>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="2" style="border-bottom: 1px solid black">
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td colspan="2">
trumpMargin2024
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
Model 1
</td>
<td>
Model 2
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
(1)
</td>
<td>
(2)
</td>
</tr>
<tr>
<td colspan="3" style="border-bottom: 1px solid black">
</td>
</tr>
<tr>
<td style="text-align:left">
reaganMargin1980
</td>
<td>
0.727<sup>***</sup>
</td>
<td>
0.876<sup>***</sup>
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
(0.155)
</td>
<td>
(0.113)
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td style="text-align:left">
evanPerc2020
</td>
<td>
</td>
<td>
0.014<sup>***</sup>
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
(0.002)
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td style="text-align:left">
Constant
</td>
<td>
-0.033
</td>
<td>
-0.275<sup>***</sup>
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
(0.033)
</td>
<td>
(0.042)
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td colspan="3" style="border-bottom: 1px solid black">
</td>
</tr>
<tr>
<td style="text-align:left">
Observations
</td>
<td>
51
</td>
<td>
51
</td>
</tr>
<tr>
<td style="text-align:left">
R<sup>2</sup>
</td>
<td>
0.310
</td>
<td>
0.655
</td>
</tr>
<tr>
<td style="text-align:left">
Adjusted R<sup>2</sup>
</td>
<td>
0.296
</td>
<td>
0.640
</td>
</tr>
<tr>
<td style="text-align:left">
Residual Std. Error
</td>
<td>
0.197 (df = 49)
</td>
<td>
0.141 (df = 48)
</td>
</tr>
<tr>
<td style="text-align:left">
F Statistic
</td>
<td>
22.011<sup>***</sup> (df = 1; 49)
</td>
<td>
45.540<sup>***</sup> (df = 2; 48)
</td>
</tr>
<tr>
<td colspan="3" style="border-bottom: 1px solid black">
</td>
</tr>
<tr>
<td style="text-align:left">
<em>Note:</em>
</td>
<td colspan="2" style="text-align:right">
<sup><em></sup>p&lt;0.1; <sup><strong></sup>p&lt;0.05; <sup></strong></em></sup>p&lt;0.01
</td>
</tr>
</table>
<p>This is an extremely useful table, very much like what you see when you read many academic journal articles that use regression analysis. At the top, you see a title that identifies the dependent variable for all regressions in the table – trumpMargin2024. The column on the left provides the variable names.</p>
<p>Once you have pasted that text into your word processor, You should go in and change variable names and the title to something that will be easy for your readers to understand. So, for example, instead of evanPerc2020, you might write “Percent evangelical, 2020” and instead of reaganMargin1980, you might write “Reagan margin, 1980”. The second column is the results of the first regression that we ran, with only reaganMargin1980 as the independent variable (you can tell that the regression did not include the age variable because the spot where the estimated coefficient for evanPerc2020 would go is blank). The “constant” is the intercept (they are the same thing). The third column is the results of the second regression analysis. If you look at the Adjusted <span class="math inline">\(R^2\)</span> row, you can see how the Adjusted <span class="math inline">\(R^2\)</span> changes as you add and subtract variables to the regression equation. When Adjusted <span class="math inline">\(R^2\)</span> decreases as you add more independent variables, that means that whatever increase in explanatory power that you get from the new variables is more than offset by the loss in degrees of freedom that you take by adding more variables.</p>
</div>
<div id="dummy-variables-in-multiple-regression" class="section level2 hasAnchor" number="9.5">
<h2><span class="header-section-number">9.5</span> Dummy variables in multiple regression<a href="regression.html#dummy-variables-in-multiple-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>For the next set of examples, we are going to use the variable ft_sccs in ANES as our dependent variable. This variable is a feeling thermometer on the the US Supreme Court, which ranges from 0 (most negative feelings) and 100 (most positive feelings).</p>
<p>We often want to include nominal variables in regression analysis. For example, we want to know whether things like gender, religion, and race might cause variation in our dependent variable. However, since the values in a nominal variable can be listed in any order, it does not make sense to talk about “increasing” the value of a nominal independent variable. We get around this by converting a nominal independent variable into a series of dummy variables (variables coded 0, for when an attribute is absent, and 1, for when it is present).</p>
<p>So, for example, the houseKnowledge variable in anes2024 is coded so that respondents that correctly identified the Republicans as the party that controlled the House of Representatives got a 1, and respondents that gave an incorrect answer got a 0. If we want to use that as an independent variable for regression analysis, we are asking R to estimate <span class="math inline">\(β_0\)</span> and <span class="math inline">\(β_1\)</span> in this equation:</p>
<p>ft_ussc=<span class="math inline">\(β_0\)</span>+ <span class="math inline">\(β_1\)</span>houseKnowledge</p>
<p>How would we interpret the results of this regression? For people wrong about the party that controls the House, the predicted value of ft_ussc would be <span class="math inline">\(β_0\)</span> (because <span class="math inline">\(β_1\)</span> multiplied by 0 equals 0). For people who know which party controls the House, the estimated value of ft_ussc would be <span class="math inline">\(β_0\)</span> + <span class="math inline">\(β_1\)</span> (because <span class="math inline">\(β_1\)</span> multiplied by 1 equals <span class="math inline">\(β_1\)</span>).</p>
<p>Let’s run this regression using this command:</p>
<div class="sourceCode" id="cb229"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb229-1"><a href="regression.html#cb229-1" tabindex="-1"></a>model3<span class="ot">&lt;-</span><span class="fu">lm</span>(ft_ussc<span class="sc">~</span>houseKnowledge, <span class="at">data=</span>anes2024)</span>
<span id="cb229-2"><a href="regression.html#cb229-2" tabindex="-1"></a><span class="fu">summary</span>(model3)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = ft_ussc ~ houseKnowledge, data = anes2024)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -50.240 -17.953   2.047  19.760  52.047 
## 
## Coefficients:
##                Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)     50.2400     0.6675  75.265  &lt; 2e-16 ***
## houseKnowledge  -2.2873     0.8244  -2.774  0.00555 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 26.52 on 4582 degrees of freedom
##   (937 observations deleted due to missingness)
## Multiple R-squared:  0.001677,   Adjusted R-squared:  0.001459 
## F-statistic: 7.697 on 1 and 4582 DF,  p-value: 0.005553</code></pre>
<p>This output tells us a few important things. First, it helps us fill out the equation from above, like this:</p>
<p>ft_ussc=50.24 + -2.29houseKnowledge</p>
<p>In other words, R is estimating that the average person who does not know which party controls the House gives the Supreme Court a 50.24, and that the average person who <em>does</em> know which party controls the House gives the Supreme court a 50.24-2.29, which is 47.95. And these estimates are both statistically significant.</p>
<p>Second, the adjusted <span class="math inline">\(R^2\)</span> value of this equation tells us that variation in House knowledge alone only explains about 0.146% of variation in feelings on the Supreme Court. Thus, there are likely a lot of major causes that are missing from this model.</p>
<p><strong>An important note:</strong>
Let’s take a minute to generate a dummy variable for those who gave the wrong answer to House question,like this:</p>
<div class="sourceCode" id="cb231"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb231-1"><a href="regression.html#cb231-1" tabindex="-1"></a>anes2024<span class="ot">&lt;-</span>anes2024 <span class="sc">%&gt;%</span> </span>
<span id="cb231-2"><a href="regression.html#cb231-2" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">nonKnowledgeable=</span><span class="fu">recode</span>(houseKnowledge,<span class="st">&#39;1&#39;</span><span class="ot">=</span><span class="dv">0</span>,<span class="st">&#39;0&#39;</span><span class="ot">=</span><span class="dv">1</span>))</span></code></pre></div>
<p>This variable is the inverse of our houseKnowledge variable. While the houseKnowledge variable is coded 1 for those who gave the correct answer to the question which party controls the House, the nonKnowledgeable variable is coded 1 for respondents that gave the <em>incorrect</em> answer. If we include that variable in the regression model above, to estimate this equation:</p>
<p>ft_ussc=<span class="math inline">\(β_0\)</span>+ <span class="math inline">\(β_1\)</span>houseKnowledge+<span class="math inline">\(β_2\)</span>nonKnowledgeable</p>
<p>we are giving R an impossible task. That it because no case will have a value of 0 for both our houseKnowledge and nonKnowledgable variables. If we ignore this impossibility, and force R to do it anyway, R does this:</p>
<div class="sourceCode" id="cb232"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb232-1"><a href="regression.html#cb232-1" tabindex="-1"></a><span class="fu">lm</span>(ft_ussc<span class="sc">~</span>houseKnowledge<span class="sc">+</span>nonKnowledgeable, <span class="at">data=</span>anes2024)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = ft_ussc ~ houseKnowledge + nonKnowledgeable, data = anes2024)
## 
## Coefficients:
##      (Intercept)    houseKnowledge  nonKnowledgeable  
##           50.240            -2.287                NA</code></pre>
<p>R essentially says “no thank you.” You will see that the coefficient for nonKnowledgeable is NA. That is because R noticed that the houseKnowledge and nonKnowledgeable variables are redundant with one another and left the nonKnowledgeable variable out. Aside from that coefficient, the rest of the output is the same as when we ran the regression with only the houseKnowledge variable.</p>
<p>The houseKnowledge variable is a nominal variable with only two values: either each respondent either answered correctly or didn’t. But it is still important to avoid including redundant variables in regression even when we are dealing with nominal independent variables with more than two values, such as race. If we enter <code>table(anes2024$race)</code>, we can see that the race variable in ANES has six values: Asian or Pacific Islander, Black, Hispanic, Multiple races, Native American, and White. Let’s see what happens when we include that variable in a regression analysis with ft_ussc as our dependent variable, like this:</p>
<div class="sourceCode" id="cb234"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb234-1"><a href="regression.html#cb234-1" tabindex="-1"></a>model4<span class="ot">&lt;-</span><span class="fu">lm</span>(ft_ussc<span class="sc">~</span>race, <span class="at">data=</span>anes2024)</span>
<span id="cb234-2"><a href="regression.html#cb234-2" tabindex="-1"></a><span class="fu">summary</span>(model4)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = ft_ussc ~ race, data = anes2024)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -52.125 -19.639   0.361  20.361  56.217 
## 
## Coefficients:
##                     Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)           52.125      2.043  25.512  &lt; 2e-16 ***
## raceBlack             -8.342      2.411  -3.460 0.000545 ***
## raceHispanic          -4.833      2.364  -2.044 0.040980 *  
## raceMultiple races    -4.096      2.873  -1.426 0.153976    
## raceNative American   -7.085      5.677  -1.248 0.212077    
## raceWhite             -2.486      2.091  -1.189 0.234511    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 26.48 on 4814 degrees of freedom
##   (701 observations deleted due to missingness)
## Multiple R-squared:  0.004912,   Adjusted R-squared:  0.003878 
## F-statistic: 4.752 on 5 and 4814 DF,  p-value: 0.0002467</code></pre>
<p>What R has done here is converted our race variable into six dummy variables: one for each value in the original race variable, and estimated the intercept and coefficient for this equation:</p>
<p>ft_ussc = <span class="math inline">\(β_0\)</span> + <span class="math inline">\(β_1\)</span>Black + <span class="math inline">\(β_2\)</span>Hispanic + <span class="math inline">\(β_3\)</span>MultipleRaces + <span class="math inline">\(β_4\)</span>NativeAmerican + <span class="math inline">\(β_5\)</span>White</p>
<p>Notice that our original race variable had six categories, but there are only five dummy variables in the model. That is because if R included the sixth value—Asian or Pacific Islander—then R would have put itself in a position where it was trying to estimate ft_ussc for a person would cannot exist in our data – someone with 0s on all 0 possible values for race. Thus, R chooses one category to be the “reference category,” and leaves that one out.</p>
<p>In the case of the race variable in ANES, R chose to leave out the first category in alphabetical order, which is “Asian or Pacific Islander.” Thus, the intercept that R estimated in the above regression (52.13) is the predicted value of feelings about the Supreme Court for someone who identified themselves as Asian or Pacific Islander (because their values on all of the other possible race dummy variables are 0).</p>
<p>-8.342 is the expected differences between someone who is an Asian or Pacific Islander and someone who is Black; in other words, Blacks seem to have a lower estimation of the Supreme Court, on average, than Asians or Pacific Islanders. And the rest of the coefficients estimate the differences between the groups that they identify and Asian Pacific Islanders.</p>
<p>R chose “Asian or Pacific Islander” as the reference category because it comes first in alphabetical order when looking at the values for the race variable. This would be useful analysis if we were writing a paper about the public opinion of Asians and Pacific Islanders. However, given that whites are the majority in our sample, we might want to compare the various ethnic minority groups in this sample with whites. To do that, we would have to first make the race variable into a factor,<a href="#fn10" class="footnote-ref" id="fnref10"><sup>10</sup></a> like this:</p>
<div class="sourceCode" id="cb236"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb236-1"><a href="regression.html#cb236-1" tabindex="-1"></a>anes2024<span class="sc">$</span>race.factor<span class="ot">&lt;-</span><span class="fu">as.factor</span>(anes2024<span class="sc">$</span>race)</span></code></pre></div>
<p>Next, we have to relevel the variable, telling R what we want the reference category to be, like this:</p>
<div class="sourceCode" id="cb237"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb237-1"><a href="regression.html#cb237-1" tabindex="-1"></a>anes2024<span class="sc">$</span>race.factor<span class="ot">&lt;-</span><span class="fu">relevel</span>(anes2024<span class="sc">$</span>race.factor, <span class="at">ref=</span><span class="st">&quot;White&quot;</span>)</span></code></pre></div>
<p>This will compare all the racial groups in this variable to whites. So, now, let’s run a regression with ft_ussc as our dependent variable and race.factor as our independent variable, like this:</p>
<div class="sourceCode" id="cb238"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb238-1"><a href="regression.html#cb238-1" tabindex="-1"></a>model5<span class="ot">&lt;-</span><span class="fu">lm</span>(ft_ussc<span class="sc">~</span>race.factor, <span class="at">data=</span>anes2024)</span>
<span id="cb238-2"><a href="regression.html#cb238-2" tabindex="-1"></a><span class="fu">summary</span>(model5)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = ft_ussc ~ race.factor, data = anes2024)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -52.125 -19.639   0.361  20.361  56.217 
## 
## Coefficients:
##                                      Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)                           49.6386     0.4457 111.381  &lt; 2e-16 ***
## race.factorAsian or Pacific Islander   2.4864     2.0912   1.189   0.2345    
## race.factorBlack                      -5.8559     1.3554  -4.320 1.59e-05 ***
## race.factorHispanic                   -2.3463     1.2699  -1.848   0.0647 .  
## race.factorMultiple races             -1.6096     2.0679  -0.778   0.4364    
## race.factorNative American            -4.5986     5.3152  -0.865   0.3870    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 26.48 on 4814 degrees of freedom
##   (701 observations deleted due to missingness)
## Multiple R-squared:  0.004912,   Adjusted R-squared:  0.003878 
## F-statistic: 4.752 on 5 and 4814 DF,  p-value: 0.0002467</code></pre>
<p>Now R is using the dummy variable for “white” as our reference category. So, interpreting this, we can see that R predicts that the average white person will give the Supreme Court a 49.64, the average Black person’s score will be 5.86 points lower than that, the average Hispanic person’s score will be 2.35 points lower than the average white person, etc. Interestingly, we can also see that Blacks are the only racial group that differs from Whites in their assessment of the Supreme Court in a statistically significant way.</p>
</div>
<div id="ordinal-variables-in-regression-analysis" class="section level2 hasAnchor" number="9.6">
<h2><span class="header-section-number">9.6</span> Ordinal variables in regression analysis<a href="regression.html#ordinal-variables-in-regression-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>If we put an ordinal variable into our regression analysis as an ordered factor (the way that R likes to treat ordinal variables), R will treat the possible values as a series of dummy variables, leave one out, and produce in the output in a way that is pretty confusing.<a href="#fn11" class="footnote-ref" id="fnref11"><sup>11</sup></a> One way around this is to convert an ordinal variable into a numeric variable, like we did in section <a href="recoding.html#factor-as-numeric">4.4</a>. Let’s try this with the outrage variable, testing the hypothesis that people that are more prone to outrage are also more likely to be outraged about the US Supreme Court, and thus produce a lower ft_ussc.</p>
<p>First, we have to check the way that the values are ordered, using this command: <code>levels(anes2024$outrage)</code>. If you enter that into your console, you will see that the variable is coded so that the lowest value is “not at all” outraged, and the highest value is “extremely” outraged. So when we convert this to numeric, it will still make sense to keep the values in this order. Now let’s convert the variable to numeric and rename it:</p>
<div class="sourceCode" id="cb240"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb240-1"><a href="regression.html#cb240-1" tabindex="-1"></a>anes2024<span class="sc">$</span>outrage2<span class="ot">&lt;-</span><span class="fu">as.numeric</span>(anes2024<span class="sc">$</span>outrage)</span></code></pre></div>
<p>Now, if you run <code>table(anes2024$outrage2)</code>, you will see that our new variable is scaled from 1 to 5. However, it will be a little easier for us if we scale this variable from 0 to 4. We can accomplish that with this command:</p>
<div class="sourceCode" id="cb241"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb241-1"><a href="regression.html#cb241-1" tabindex="-1"></a>anes2024<span class="sc">$</span>outrage2<span class="ot">&lt;-</span>anes2024<span class="sc">$</span>outrage2<span class="dv">-1</span></span></code></pre></div>
<p>Now let’s try our regression analysis with our new variable:</p>
<div class="sourceCode" id="cb242"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb242-1"><a href="regression.html#cb242-1" tabindex="-1"></a>model6<span class="ot">&lt;-</span><span class="fu">lm</span>(ft_ussc<span class="sc">~</span>outrage2, <span class="at">data=</span>anes2024)</span>
<span id="cb242-2"><a href="regression.html#cb242-2" tabindex="-1"></a><span class="fu">summary</span>(model6)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = ft_ussc ~ outrage2, data = anes2024)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -53.17 -18.36   1.64  19.24  56.45 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  43.5532     0.7590  57.385  &lt; 2e-16 ***
## outrage2      2.4032     0.2953   8.137 5.14e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 26.32 on 4658 degrees of freedom
##   (861 observations deleted due to missingness)
## Multiple R-squared:  0.01402,    Adjusted R-squared:  0.0138 
## F-statistic: 66.21 on 1 and 4658 DF,  p-value: 5.142e-16</code></pre>
<p>Interestingly, these results show that, on average, someone with an outrage score of 0 (meaning they were not at all outraged) gave the Supreme Court a 43.55, but a one point increase in the outrage scale is associated with a 2.4 point <em>increase</em> in positive feelings toward the Supreme Court. Perhaps outraged people trust the Supreme Court to address their sources of outrage?</p>
</div>
<div id="graphing-multiple-regression" class="section level2 hasAnchor" number="9.7">
<h2><span class="header-section-number">9.7</span> Graphing multiple regression<a href="regression.html#graphing-multiple-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>When you ask R to calculate a bivariate OLS regression, you are actually asking R to estimate the formula for a line. This is relatively easy to represent on a two-dimensional scatterplot. You can have R plot all of the points that it is using to estimate the line, as well as the line itself (like we did in Chapter 8). When you add a second independent variable, you are asking R to estimate the formula for a plane, which becomes harder to graph, and when you add a third, you are asking R to estimate the formula for a three-dimensional object, which is even harder to graph. Adding four or more independent variable makes it impossible to graph the whole relationship about which you are asking R to theorize. However, there are still ways to represent part of the relationship. For example, let’s say that we have asked R to run this regression:</p>
<pre><code>summary(lm(ft_ussc~ft_liberals+race.factor, data=anes2024))</code></pre>
<p>When we do this, we are asking R to estimate the intercept and coefficients in this equation:</p>
<p>ft_ussc=<span class="math inline">\(β_0\)</span>+ <span class="math inline">\(β_1\)</span>ft_liberals + <span class="math inline">\(β_2\)</span>AsianPacificIslander + <span class="math inline">\(β_3\)</span>Black + <span class="math inline">\(β_4\)</span>Hispanic + <span class="math inline">\(β_5\)</span>MultipleRaces + <span class="math inline">\(β_6\)</span>NativeAmerican</p>
<p>with “White” as the reference category for race. One way that we can graphically represent this relationship is by using <em>facets</em>. In other words, we can ask R to make a different scatterplot for every value of our nominal race variable, using the following code.</p>
<div class="sourceCode" id="cb245"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb245-1"><a href="regression.html#cb245-1" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data=</span>anes2024 <span class="sc">%&gt;%</span> <span class="fu">filter</span>(<span class="sc">!</span><span class="fu">is.na</span>(race.factor)), <span class="fu">aes</span>(<span class="at">x=</span>ft_liberals, <span class="at">y=</span>ft_ussc)) <span class="sc">+</span></span>
<span id="cb245-2"><a href="regression.html#cb245-2" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">size=</span><span class="dv">2</span>, <span class="at">alpha=</span>.<span class="dv">5</span>, <span class="at">color=</span><span class="st">&quot;purple&quot;</span>) <span class="sc">+</span></span>
<span id="cb245-3"><a href="regression.html#cb245-3" tabindex="-1"></a>  <span class="fu">theme_bw</span>()<span class="sc">+</span></span>
<span id="cb245-4"><a href="regression.html#cb245-4" tabindex="-1"></a>  <span class="co">#add axis labels</span></span>
<span id="cb245-5"><a href="regression.html#cb245-5" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Feelings about liberals &amp; Supreme Court&quot;</span>, </span>
<span id="cb245-6"><a href="regression.html#cb245-6" tabindex="-1"></a>       <span class="at">subtitle=</span><span class="st">&quot;ANES 2024&quot;</span>,</span>
<span id="cb245-7"><a href="regression.html#cb245-7" tabindex="-1"></a>       <span class="at">x=</span><span class="st">&quot;Feelings about liberals&quot;</span>, </span>
<span id="cb245-8"><a href="regression.html#cb245-8" tabindex="-1"></a>       <span class="at">y=</span><span class="st">&quot;Feeling about Supreme Court&quot;</span>, <span class="at">color=</span><span class="cn">NULL</span>)<span class="sc">+</span></span>
<span id="cb245-9"><a href="regression.html#cb245-9" tabindex="-1"></a>  <span class="co">#add regression line</span></span>
<span id="cb245-10"><a href="regression.html#cb245-10" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method=</span><span class="st">&#39;lm&#39;</span>, <span class="at">color=</span><span class="st">&quot;BLACK&quot;</span>)<span class="sc">+</span></span>
<span id="cb245-11"><a href="regression.html#cb245-11" tabindex="-1"></a>  <span class="co">#make different graphs for every value of a nominal or ordinal variable</span></span>
<span id="cb245-12"><a href="regression.html#cb245-12" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span>race.factor)</span></code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-139-1.png" width="672" /></p>
<p>This graph shows us the relationship between feelings about liberals and feelings about the US Supreme court at all values of our race variable. Notice how much more substantially negative the relationship is among whites than it is among other racial groups.</p>
</div>
<div id="review-of-this-chapters-commands-8" class="section level2 hasAnchor" number="9.8">
<h2><span class="header-section-number">9.8</span> Review of this chapter’s commands<a href="regression.html#review-of-this-chapters-commands-8" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<table>
<colgroup>
<col width="9%" />
<col width="85%" />
<col width="5%" />
</colgroup>
<thead>
<tr>
<th align="left">Command</th>
<th align="left">Purpose</th>
<th align="left">Library</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">stargazer()</td>
<td align="left">Use this code to generate a beautiful table displaying the results of one or more regressions.</td>
<td align="left">stargazer</td>
</tr>
<tr>
<td align="left">as.factor()</td>
<td align="left">Changes a character variable to a factor. Necessary when you want to set a different reference category when including a nominal variable in regression analysis.</td>
<td align="left">Base R</td>
</tr>
<tr>
<td align="left">relevel(, ref=““)</td>
<td align="left">Changes the reference category of a factor. Necessary when you want to set a different reference category when including a nominal variable in regression analysis.</td>
<td align="left">Base R</td>
</tr>
</tbody>
</table>

</div>
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-Hlavac" class="csl-entry">
Hlavac, Marek. 2022. <em>Stargazer: Well-Formatted Regression and Summary Statistics Tables</em>. Bratislava, Slovakia: Social Policy Institute. <a href="https://CRAN.R-project.org/package=stargazer">https://CRAN.R-project.org/package=stargazer</a>.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="8">
<li id="fn8"><p>Stargazer is designed by Hlavac <span class="citation">(<a href="#ref-Hlavac">2022</a>)</span>.<a href="regression.html#fnref8" class="footnote-back">↩︎</a></p></li>
<li id="fn9"><p>To test this, you can use this command: <code>model2.data %&gt;%  dplyr::select(state,abs.resid) %&gt;% arrange(abs.resid) %&gt;%  head()</code><a href="regression.html#fnref9" class="footnote-back">↩︎</a></p></li>
<li id="fn10"><p>Because race is a nominal variable, we are making it into a non-ordered factor. If it were an ordinal variable, we would want to make it an ordered factor.<a href="regression.html#fnref10" class="footnote-back">↩︎</a></p></li>
<li id="fn11"><p>if you don’t believe me, enter <code>lm(ft_ussc~outrage,data=anes2024)</code> into the Console.<a href="regression.html#fnref11" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="pearsons-r.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="wild.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/09-regression.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
